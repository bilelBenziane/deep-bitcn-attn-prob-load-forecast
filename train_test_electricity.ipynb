{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126234c3-126a-404c-9b54-df173d17dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/uci_electricity/bitcn_att_skip/bitcn_att_skip_seed=0_lr=0.001_bs=64_N=6_NATT=4_d_hidden=25_heads=5\n",
      "Epoch 1/10\n",
      "  Train loss: -0.8700 Time: 75.49s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1801.65/0.69/0.078/0.142/0.116\n",
      "         p10/p50/p90/mp50 loss: 0.037/0.078/0.040/0.062\n",
      "  Validation/Test loss: -0.1717 Time: 6.71s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1807.83/0.71/0.095/0.155/0.151\n",
      "         p10/p50/p90/mp50 loss: 0.056/0.095/0.042/0.077\n",
      "Epoch 2/10\n",
      "  Train loss: -1.2942 Time: 67.81s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1076.02/0.41/0.048/0.081/0.083\n",
      "         p10/p50/p90/mp50 loss: 0.022/0.048/0.026/0.038\n",
      "  Validation/Test loss: -0.3500 Time: 5.49s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1582.32/0.62/0.082/0.136/0.139\n",
      "         p10/p50/p90/mp50 loss: 0.044/0.082/0.042/0.067\n",
      "Epoch 3/10\n",
      "  Train loss: -1.3674 Time: 58.96s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1053.68/0.40/0.046/0.073/0.079\n",
      "         p10/p50/p90/mp50 loss: 0.021/0.046/0.024/0.036\n",
      "  Validation/Test loss: -0.7179 Time: 5.18s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1585.85/0.62/0.073/0.116/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.033/0.073/0.044/0.059\n",
      "Epoch 4/10\n",
      "  Train loss: -1.4041 Time: 58.27s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1051.45/0.40/0.045/0.069/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.045/0.024/0.036\n",
      "  Validation/Test loss: -0.4954 Time: 5.33s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1589.49/0.62/0.079/0.123/0.124\n",
      "         p10/p50/p90/mp50 loss: 0.044/0.079/0.039/0.064\n",
      "Epoch 5/10\n",
      "  Train loss: -1.4241 Time: 56.19s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1040.57/0.40/0.044/0.066/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.023/0.035\n",
      "  Validation/Test loss: -0.6491 Time: 5.26s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1554.09/0.61/0.072/0.118/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.035/0.072/0.044/0.060\n",
      "Epoch 6/10\n",
      "  Train loss: -1.4419 Time: 56.32s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1033.07/0.40/0.043/0.065/0.076\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.043/0.023/0.035\n",
      "  Validation/Test loss: -0.7160 Time: 4.82s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1514.95/0.59/0.069/0.115/0.115\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.069/0.040/0.057\n",
      "Epoch 7/10\n",
      "  Train loss: -1.4565 Time: 58.10s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1032.55/0.40/0.043/0.063/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.6174 Time: 5.03s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1498.35/0.59/0.073/0.121/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.038/0.073/0.039/0.060\n",
      "Epoch 8/10\n",
      "  Train loss: -1.4698 Time: 57.92s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1024.87/0.39/0.043/0.063/0.074\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.5391 Time: 5.18s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1474.35/0.58/0.076/0.126/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.042/0.076/0.039/0.062\n",
      "  Validation/Test loss: -0.7208 Time: 5.20s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 772.60/0.35/0.072/0.122/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.039/0.072/0.036/0.059\n",
      "experiments/uci_electricity/bitcn_att_skip/bitcn_att_skip_seed=1_lr=0.001_bs=64_N=6_NATT=4_d_hidden=25_heads=5\n",
      "Epoch 1/10\n",
      "  Train loss: -0.9208 Time: 59.54s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1686.56/0.65/0.074/0.131/0.112\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.074/0.038/0.059\n",
      "  Validation/Test loss: -0.6498 Time: 5.36s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1549.89/0.61/0.076/0.124/0.127\n",
      "         p10/p50/p90/mp50 loss: 0.038/0.076/0.040/0.061\n",
      "Epoch 2/10\n",
      "  Train loss: -1.3128 Time: 59.35s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1062.19/0.41/0.047/0.078/0.081\n",
      "         p10/p50/p90/mp50 loss: 0.022/0.047/0.025/0.038\n",
      "  Validation/Test loss: -0.6418 Time: 5.54s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1494.16/0.59/0.074/0.118/0.128\n",
      "         p10/p50/p90/mp50 loss: 0.035/0.074/0.039/0.059\n",
      "Epoch 3/10\n",
      "  Train loss: -1.3736 Time: 57.28s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1046.20/0.40/0.046/0.071/0.079\n",
      "         p10/p50/p90/mp50 loss: 0.021/0.046/0.024/0.036\n",
      "  Validation/Test loss: -0.8760 Time: 5.51s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1461.80/0.57/0.068/0.103/0.107\n",
      "         p10/p50/p90/mp50 loss: 0.027/0.068/0.045/0.055\n",
      "Epoch 4/10\n",
      "  Train loss: -1.4081 Time: 59.68s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1033.20/0.40/0.044/0.067/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.024/0.035\n",
      "  Validation/Test loss: -0.3549 Time: 5.43s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1608.74/0.63/0.085/0.136/0.131\n",
      "         p10/p50/p90/mp50 loss: 0.050/0.085/0.039/0.069\n",
      "Epoch 5/10\n",
      "  Train loss: -1.4286 Time: 57.36s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1018.92/0.39/0.044/0.065/0.076\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.023/0.035\n",
      "  Validation/Test loss: -0.5058 Time: 5.31s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1508.35/0.59/0.077/0.129/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.043/0.077/0.039/0.063\n",
      "Epoch 6/10\n",
      "  Train loss: -1.4453 Time: 59.50s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1027.45/0.39/0.043/0.063/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.043/0.023/0.035\n",
      "  Validation/Test loss: -0.5843 Time: 5.47s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1412.47/0.55/0.072/0.121/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.038/0.072/0.039/0.059\n",
      "Epoch 7/10\n",
      "  Train loss: -1.4604 Time: 58.86s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1013.85/0.39/0.043/0.062/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.5216 Time: 6.00s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1464.58/0.57/0.075/0.123/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.042/0.075/0.039/0.061\n",
      "Epoch 8/10\n",
      "  Train loss: -1.4706 Time: 63.24s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1020.14/0.39/0.043/0.061/0.074\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.7823 Time: 5.18s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1445.41/0.57/0.066/0.107/0.108\n",
      "         p10/p50/p90/mp50 loss: 0.031/0.066/0.041/0.054\n",
      "  Validation/Test loss: -0.8770 Time: 5.08s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 892.90/0.40/0.068/0.101/0.110\n",
      "         p10/p50/p90/mp50 loss: 0.031/0.068/0.045/0.056\n",
      "experiments/uci_electricity/bitcn_att_skip/bitcn_att_skip_seed=2_lr=0.001_bs=64_N=6_NATT=4_d_hidden=25_heads=5\n",
      "Epoch 1/10\n",
      "  Train loss: -0.8579 Time: 59.41s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1784.95/0.68/0.079/0.145/0.117\n",
      "         p10/p50/p90/mp50 loss: 0.037/0.079/0.040/0.063\n",
      "  Validation/Test loss: -0.5563 Time: 5.15s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1606.61/0.63/0.079/0.128/0.136\n",
      "         p10/p50/p90/mp50 loss: 0.032/0.079/0.053/0.065\n",
      "Epoch 2/10\n",
      "  Train loss: -1.2988 Time: 58.95s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1072.93/0.41/0.048/0.082/0.082\n",
      "         p10/p50/p90/mp50 loss: 0.022/0.048/0.025/0.038\n",
      "  Validation/Test loss: -0.8435 Time: 5.34s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1576.35/0.62/0.069/0.107/0.117\n",
      "         p10/p50/p90/mp50 loss: 0.030/0.069/0.044/0.057\n",
      "Epoch 3/10\n",
      "  Train loss: -1.3665 Time: 58.17s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1055.73/0.40/0.046/0.077/0.079\n",
      "         p10/p50/p90/mp50 loss: 0.021/0.046/0.024/0.036\n",
      "  Validation/Test loss: -0.7523 Time: 5.09s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1507.41/0.59/0.072/0.110/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.072/0.040/0.058\n",
      "Epoch 4/10\n",
      "  Train loss: -1.4000 Time: 57.01s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1044.78/0.40/0.044/0.072/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.024/0.035\n",
      "  Validation/Test loss: -0.8616 Time: 5.36s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1485.80/0.58/0.067/0.104/0.110\n",
      "         p10/p50/p90/mp50 loss: 0.030/0.067/0.040/0.054\n",
      "Epoch 5/10\n",
      "  Train loss: -1.4207 Time: 59.32s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1036.74/0.40/0.044/0.069/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.023/0.035\n",
      "  Validation/Test loss: -0.6229 Time: 5.14s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1476.68/0.58/0.072/0.120/0.119\n",
      "         p10/p50/p90/mp50 loss: 0.038/0.072/0.039/0.059\n",
      "Epoch 6/10\n",
      "  Train loss: -1.4378 Time: 54.46s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1029.10/0.39/0.043/0.066/0.076\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.043/0.023/0.035\n",
      "  Validation/Test loss: -0.8617 Time: 5.37s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1446.37/0.57/0.066/0.105/0.107\n",
      "         p10/p50/p90/mp50 loss: 0.030/0.066/0.040/0.054\n",
      "Epoch 7/10\n",
      "  Train loss: -1.4548 Time: 59.61s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1025.71/0.39/0.043/0.064/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.7249 Time: 5.19s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1492.85/0.59/0.071/0.112/0.114\n",
      "         p10/p50/p90/mp50 loss: 0.035/0.071/0.041/0.058\n",
      "Epoch 8/10\n",
      "  Train loss: -1.4648 Time: 57.79s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1031.80/0.40/0.043/0.063/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.8979 Time: 5.24s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1473.74/0.58/0.065/0.102/0.105\n",
      "         p10/p50/p90/mp50 loss: 0.029/0.065/0.042/0.054\n",
      "Epoch 9/10\n",
      "  Train loss: -1.4771 Time: 58.22s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1031.56/0.40/0.043/0.062/0.074\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.8783 Time: 5.24s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1432.33/0.56/0.064/0.102/0.105\n",
      "         p10/p50/p90/mp50 loss: 0.029/0.064/0.042/0.053\n",
      "Epoch 10/10\n",
      "  Train loss: -1.4868 Time: 58.71s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1021.19/0.39/0.042/0.060/0.073\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.042/0.023/0.034\n",
      "  Validation/Test loss: -0.8653 Time: 5.91s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1402.22/0.55/0.065/0.111/0.105\n",
      "         p10/p50/p90/mp50 loss: 0.032/0.065/0.038/0.053\n",
      "  Validation/Test loss: -0.9199 Time: 5.56s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 729.64/0.33/0.063/0.094/0.103\n",
      "         p10/p50/p90/mp50 loss: 0.033/0.063/0.036/0.052\n",
      "experiments/uci_electricity/bitcn_att_skip/bitcn_att_skip_seed=3_lr=0.001_bs=64_N=6_NATT=4_d_hidden=25_heads=5\n",
      "Epoch 1/10\n",
      "  Train loss: -0.9135 Time: 57.20s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1641.83/0.63/0.074/0.133/0.112\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.074/0.038/0.059\n",
      "  Validation/Test loss: -0.7551 Time: 5.33s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1577.90/0.62/0.073/0.115/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.032/0.073/0.046/0.059\n",
      "Epoch 2/10\n",
      "  Train loss: -1.3133 Time: 57.89s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1085.53/0.42/0.048/0.079/0.082\n",
      "         p10/p50/p90/mp50 loss: 0.022/0.048/0.025/0.038\n",
      "  Validation/Test loss: -0.7933 Time: 4.84s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1563.20/0.61/0.071/0.111/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.031/0.071/0.045/0.058\n",
      "Epoch 3/10\n",
      "  Train loss: -1.3752 Time: 58.28s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1055.36/0.40/0.045/0.072/0.079\n",
      "         p10/p50/p90/mp50 loss: 0.021/0.045/0.024/0.036\n",
      "  Validation/Test loss: -0.7813 Time: 5.43s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1528.51/0.60/0.069/0.107/0.114\n",
      "         p10/p50/p90/mp50 loss: 0.033/0.069/0.041/0.056\n",
      "Epoch 4/10\n",
      "  Train loss: -1.4063 Time: 59.24s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1050.39/0.40/0.045/0.069/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.045/0.024/0.036\n",
      "  Validation/Test loss: -0.5335 Time: 5.44s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1664.44/0.65/0.080/0.121/0.122\n",
      "         p10/p50/p90/mp50 loss: 0.047/0.080/0.039/0.065\n",
      "Epoch 5/10\n",
      "  Train loss: -1.4308 Time: 56.44s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1035.39/0.40/0.044/0.067/0.076\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.023/0.035\n",
      "  Validation/Test loss: -0.7909 Time: 5.28s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1605.90/0.63/0.071/0.107/0.109\n",
      "         p10/p50/p90/mp50 loss: 0.039/0.071/0.038/0.059\n",
      "Epoch 6/10\n",
      "  Train loss: -1.4459 Time: 59.09s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1034.67/0.40/0.043/0.065/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.043/0.023/0.035\n",
      "  Validation/Test loss: -0.6146 Time: 5.12s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1680.87/0.66/0.078/0.118/0.120\n",
      "         p10/p50/p90/mp50 loss: 0.045/0.078/0.039/0.064\n",
      "Epoch 7/10\n",
      "  Train loss: -1.4608 Time: 57.93s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1036.95/0.40/0.043/0.063/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.6776 Time: 5.14s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1624.16/0.64/0.074/0.113/0.115\n",
      "         p10/p50/p90/mp50 loss: 0.042/0.074/0.038/0.061\n",
      "  Validation/Test loss: -0.7940 Time: 5.35s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1069.57/0.48/0.073/0.112/0.121\n",
      "         p10/p50/p90/mp50 loss: 0.033/0.073/0.049/0.061\n",
      "experiments/uci_electricity/bitcn_att_skip/bitcn_att_skip_seed=4_lr=0.001_bs=64_N=6_NATT=4_d_hidden=25_heads=5\n",
      "Epoch 1/10\n",
      "  Train loss: -0.9038 Time: 58.46s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1735.47/0.66/0.076/0.136/0.116\n",
      "         p10/p50/p90/mp50 loss: 0.035/0.076/0.039/0.060\n",
      "  Validation/Test loss: -0.7117 Time: 5.33s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1619.71/0.64/0.075/0.118/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.075/0.043/0.061\n",
      "Epoch 2/10\n",
      "  Train loss: -1.3106 Time: 57.08s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1077.87/0.41/0.048/0.080/0.082\n",
      "         p10/p50/p90/mp50 loss: 0.022/0.048/0.025/0.038\n",
      "  Validation/Test loss: -0.7694 Time: 5.20s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1531.45/0.60/0.071/0.110/0.116\n",
      "         p10/p50/p90/mp50 loss: 0.032/0.071/0.040/0.057\n",
      "Epoch 3/10\n",
      "  Train loss: -1.3771 Time: 57.57s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1048.05/0.40/0.045/0.073/0.079\n",
      "         p10/p50/p90/mp50 loss: 0.021/0.045/0.024/0.036\n",
      "  Validation/Test loss: -0.7285 Time: 5.29s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1544.21/0.61/0.071/0.110/0.115\n",
      "         p10/p50/p90/mp50 loss: 0.036/0.071/0.039/0.058\n",
      "Epoch 4/10\n",
      "  Train loss: -1.4115 Time: 59.02s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1051.18/0.40/0.044/0.068/0.077\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.024/0.035\n",
      "  Validation/Test loss: -0.7921 Time: 5.13s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1503.11/0.59/0.068/0.108/0.111\n",
      "         p10/p50/p90/mp50 loss: 0.031/0.068/0.041/0.056\n",
      "Epoch 5/10\n",
      "  Train loss: -1.4334 Time: 58.49s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1031.55/0.40/0.044/0.066/0.076\n",
      "         p10/p50/p90/mp50 loss: 0.020/0.044/0.023/0.035\n",
      "  Validation/Test loss: -0.6588 Time: 5.29s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1431.10/0.56/0.069/0.116/0.117\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.069/0.039/0.057\n",
      "Epoch 6/10\n",
      "  Train loss: -1.4515 Time: 58.46s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1019.36/0.39/0.043/0.064/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.5774 Time: 5.10s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1496.14/0.59/0.072/0.123/0.122\n",
      "         p10/p50/p90/mp50 loss: 0.041/0.072/0.038/0.060\n",
      "Epoch 7/10\n",
      "  Train loss: -1.4644 Time: 57.12s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1021.65/0.39/0.043/0.063/0.075\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.043/0.023/0.034\n",
      "  Validation/Test loss: -0.7078 Time: 5.13s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1458.83/0.57/0.070/0.118/0.116\n",
      "         p10/p50/p90/mp50 loss: 0.035/0.070/0.039/0.057\n",
      "Epoch 8/10\n",
      "  Train loss: -1.4767 Time: 57.99s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1022.78/0.39/0.042/0.062/0.074\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.042/0.023/0.034\n",
      "  Validation/Test loss: -0.7071 Time: 5.42s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1438.32/0.56/0.068/0.114/0.114\n",
      "         p10/p50/p90/mp50 loss: 0.034/0.068/0.038/0.055\n",
      "Epoch 9/10\n",
      "  Train loss: -1.4884 Time: 57.81s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1025.92/0.39/0.042/0.061/0.074\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.042/0.022/0.034\n",
      "  Validation/Test loss: -0.7966 Time: 5.27s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1408.02/0.55/0.066/0.116/0.109\n",
      "         p10/p50/p90/mp50 loss: 0.032/0.066/0.038/0.054\n",
      "Epoch 10/10\n",
      "  Train loss: -1.4965 Time: 56.71s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1011.39/0.39/0.042/0.061/0.073\n",
      "         p10/p50/p90/mp50 loss: 0.019/0.042/0.022/0.033\n",
      "  Validation/Test loss: -0.4796 Time: 5.50s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 1487.30/0.58/0.077/0.130/0.123\n",
      "         p10/p50/p90/mp50 loss: 0.047/0.077/0.037/0.063\n",
      "  Validation/Test loss: -0.8162 Time: 5.38s\n",
      "         RMSE/NRMSE/ND/MAPE/sMAPE loss: 813.71/0.36/0.068/0.106/0.106\n",
      "         p10/p50/p90/mp50 loss: 0.039/0.068/0.036/0.056\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'end_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 157\u001b[0m\n\u001b[1;32m    153\u001b[0m     _, loss_test, yhat_tot, y_tot, x_tot, df_test \u001b[38;5;241m=\u001b[39m loop(model, test_set, optimizer, batch_size, id_samples_test, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaling\u001b[38;5;241m=\u001b[39mscaling)    \n\u001b[1;32m    154\u001b[0m     df_test\u001b[38;5;241m.\u001b[39mto_csv(filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 157\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mend_time\u001b[49m \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Convert to hours, minutes, and seconds\u001b[39;00m\n\u001b[1;32m    160\u001b[0m hours, rem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(elapsed_time, \u001b[38;5;241m3600\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'end_time' is not defined"
     ]
    }
   ],
   "source": [
    "# command to launch this code ijn the background\n",
    "# nohup python3 train_test_electricity.py > train_test_electricity.log 2>&1 &\n",
    "\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from lib.utils import fix_seed, instantiate_model, read_table, get_emb\n",
    "from lib.train import loop\n",
    "from data.datasets import timeseries_dataset\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "num_cores = 4\n",
    "torch.set_num_threads(2)\n",
    "#%% Initialize parameters for datasets\n",
    "datasets = ['uci_electricity','uci_traffic','kaggle_favorita', 'kaggle_webtraffic', 'kaggle_m5']\n",
    "dim_inputseqlens = [168, 168, 90, 90, 90]\n",
    "dim_outputseqlens = [24, 24, 28, 30, 28]\n",
    "dim_maxseqlens = [500, 500, 150, 150, 119]\n",
    "#%% Initiate experiment\n",
    "dataset_id = 0\n",
    "cuda = 0\n",
    "seed = 0\n",
    "\n",
    "num_samples_train = 1500000 if datasets[dataset_id] == 'kaggle_m5' else 500000\n",
    "num_samples_validate = 30000 if datasets[dataset_id] == 'kaggle_m5' else 10000\n",
    "\n",
    "num_samples_test = 10000\n",
    "\n",
    "fix_seed(seed)\n",
    "early_stopping_patience = 5\n",
    "scaling = True\n",
    "epochs = 100\n",
    "epochs = 10\n",
    "#%% Load data\n",
    "dataset_name = datasets[dataset_id]\n",
    "experiment_dir = 'experiments/'+dataset_name\n",
    "dim_inputseqlen = dim_inputseqlens[dataset_id] # Input sequence length\n",
    "dim_outputseqlen = dim_outputseqlens[dataset_id]  # Output prediction length\n",
    "dim_maxseqlen = dim_maxseqlens[dataset_id]\n",
    "# Import data\n",
    "dset = timeseries_dataset(dataset_name, dim_inputseqlen, dim_outputseqlen, dim_maxseqlen)\n",
    "training_set = dset.load('train')\n",
    "validation_set = dset.load('validate')\n",
    "test_set = dset.load('test')\n",
    "\n",
    "# Initialize sample sets\n",
    "id_samples_train = torch.randperm(len(training_set))[:num_samples_train]\n",
    "id_samples_validate = torch.randperm(len(validation_set))[:num_samples_validate]\n",
    "id_samples_test = torch.randperm(len(test_set))[:num_samples_test]\n",
    "\n",
    "#%% Algorithm parameters\n",
    "device = torch.device(cuda)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "file_experiments = experiment_dir + f'/experiments_{dataset_name}.csv'\n",
    "hyperparams_filename = f\"{experiment_dir}/\"\n",
    "d_emb = get_emb(dataset_name)\n",
    "\n",
    "\n",
    "algorithm = 'bitcn_att_skip'\n",
    "\n",
    "# main loop to test different version of this architecture\n",
    "time_per_cong=[]\n",
    "for learning_rate in [0.001]: # you can fine tune it using different values (usually 0.0001, 0.0005, 0.001 )\n",
    "    for batch_size in [64]: #you can fine tune it using other values (64,128,256,512)\n",
    "         for d_hidden in [25]: #you cna fine tune it usqing other values like 5,10;15;20;25;30,....\n",
    "            start_time = time.time()    \n",
    "             \n",
    "            for seed in  [0,1,2,3,4]: # training a testing the model on multiple seeds and computing the average error is much more robust\n",
    "                N = 6\n",
    "                NATT = 4\n",
    "                fix_seed(seed)\n",
    "                dropout = 0.1\n",
    "                kernel_size = 9\n",
    "                heads = 5\n",
    "                \n",
    "                params= [training_set.d_lag, training_set.d_cov, d_emb,training_set.dim_output,d_hidden, dropout, N,kernel_size,NATT,heads]\n",
    "            \n",
    "                ## initi the model\n",
    "                filename = f\"{experiment_dir}/{algorithm}/{algorithm}_seed={seed}_lr={learning_rate}_bs={batch_size}_N={N}_NATT={NATT}_d_hidden={d_hidden}_heads={heads}\"\n",
    "                print(filename)\n",
    "                if not os.path.isdir(f\"{experiment_dir}/{algorithm}\"): os.makedirs(f\"{experiment_dir}/{algorithm}\")\n",
    "                fix_seed(seed)\n",
    "                n_batch_train = (len(id_samples_train) + batch_size - 1) // batch_size \n",
    "                n_batch_validate = (len(id_samples_validate) + batch_size - 1) // batch_size\n",
    "                if 'model' in locals(): del model\n",
    "            \n",
    "                model = instantiate_model(algorithm)(*params).to(device)   \n",
    "            \n",
    "                ############## Train #################\n",
    "                optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "                loss_train = np.zeros((epochs))\n",
    "                loss_validate = np.zeros((epochs))\n",
    "                loss_validate_best = 1e6\n",
    "                early_stopping_counter = 0\n",
    "                best_epoch = 0\n",
    "            \n",
    "                ## model train / valid code \n",
    "                ## Traibn valid \n",
    "                for epoch in range(epochs):\n",
    "                    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "                    model, loss_train[epoch], _, _, _, _ = loop(model, training_set, optimizer, batch_size, id_samples_train, train=True, metrics=True, scaling=scaling)    \n",
    "                    _, loss_validate[epoch], yhat_tot, y_tot, x_tot, df_validate = loop(model, validation_set, optimizer, batch_size, id_samples_validate, train=False, metrics=True, scaling=scaling)    \n",
    "                    if loss_validate[epoch] < loss_validate_best:\n",
    "                        torch.save({'epoch':epoch, \n",
    "                                   'model_state_dict':model.state_dict(),\n",
    "                                   'optimizer_state_dict':optimizer.state_dict()}, filename)\n",
    "                        df_validate.to_csv(filename + '_validate.csv')\n",
    "                        loss_validate_best = loss_validate[epoch]\n",
    "                        early_stopping_counter = 0\n",
    "                    else:\n",
    "                        early_stopping_counter += 1\n",
    "                    if (early_stopping_counter == early_stopping_patience) | (epoch == epochs - 1):\n",
    "                        loss_train = loss_train / n_batch_train\n",
    "                        loss_validate = loss_validate / n_batch_validate\n",
    "                        df_loss = pd.DataFrame({'Validation_loss':loss_validate,'Training_loss':loss_train})\n",
    "                        df_loss.to_csv(filename + '_loss.csv')\n",
    "                        break\n",
    "             \n",
    "                params= [test_set.d_lag, test_set.d_cov, d_emb,test_set.dim_output,d_hidden, dropout, N,kernel_size,NATT,heads]\n",
    "                filename = f\"{experiment_dir}/{algorithm}/{algorithm}_seed={seed}_lr={learning_rate}_bs={batch_size}_N={N}_NATT={NATT}_d_hidden={d_hidden}_heads={heads}\"\n",
    "            \n",
    "                fix_seed(seed)\n",
    "                n_batch_test = (len(id_samples_test) + batch_size - 1) // batch_size\n",
    "                if 'model' in locals(): del model\n",
    "                model = instantiate_model(algorithm)(*params) \n",
    "            \n",
    "                #print(filename)\n",
    "                checkpoint = torch.load(filename)\n",
    "            \n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                model.to(device)\n",
    "                optimizer=None\n",
    "                _, loss_test, yhat_tot, y_tot, x_tot, df_test = loop(model, test_set, optimizer, batch_size, id_samples_test, train=False, metrics=True, scaling=scaling)    \n",
    "                df_test.to_csv(filename + '_test.csv')\n",
    "                        \n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "\n",
    "            # Convert to hours, minutes, and seconds\n",
    "            hours, rem = divmod(elapsed_time, 3600)\n",
    "            minutes, seconds = divmod(rem, 60)\n",
    "            time_per_cong.append(elapsed_time)\n",
    "            print(f\"Training completed in {int(hours)} hours, {int(minutes)} minutes, and {seconds:.2f} seconds.\")                                            \n",
    "                                    \n",
    "\n",
    "with open('electricity_time_per_conf.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(time_per_cong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321c036-ab39-47ce-9274-e90c2daca933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mujta)",
   "language": "python",
   "name": "mujta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
